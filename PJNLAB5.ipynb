{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Orley74/Przetwarzanie_jezyka_naturalnego/blob/main/PJNLAB5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr6Vf5gnTQvc"
      },
      "outputs": [],
      "source": [
        "# Run this cell to import packages.\n",
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pulling resources necessary to run code\n",
        "# they will be stored in '/content/nlp-resources-edu/05_Embedding_lab/' folder\n",
        "\n",
        "!git clone  https://github.com/mmazurek-wat/nlp-resources-edu.git\n",
        "resource_path = '/content/nlp-resources-edu/05_Embedding_lab/'\n",
        "\n",
        "sys.path.append(resource_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69TXjjZRTdwz",
        "outputId": "139dcc9f-34b4-46e4-98be-661c414b7f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nlp-resources-edu'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 25 (delta 3), reused 18 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (25/25), 3.75 MiB | 3.50 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "capitals_file = 'capitals.txt'\n",
        "capitals_file_path = path.join(resource_path, capitals_file)\n",
        "data = pd.read_csv(capitals_file_path, delimiter=' ')\n",
        "data.columns = ['city1', 'country1', 'city2', 'country2']\n",
        "\n",
        "# print first five elements in the DataFrame\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eri__RsZTfmR",
        "outputId": "1aaefecf-2bbd-4d47-8429-06776bffd07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    city1 country1    city2     country2\n",
              "0  Athens   Greece  Bangkok     Thailand\n",
              "1  Athens   Greece  Beijing        China\n",
              "2  Athens   Greece   Berlin      Germany\n",
              "3  Athens   Greece     Bern  Switzerland\n",
              "4  Athens   Greece    Cairo        Egypt"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad57896a-9ed1-4b83-bc90-5eaadeeb12d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city1</th>\n",
              "      <th>country1</th>\n",
              "      <th>city2</th>\n",
              "      <th>country2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Bangkok</td>\n",
              "      <td>Thailand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Beijing</td>\n",
              "      <td>China</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Bern</td>\n",
              "      <td>Switzerland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Athens</td>\n",
              "      <td>Greece</td>\n",
              "      <td>Cairo</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad57896a-9ed1-4b83-bc90-5eaadeeb12d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad57896a-9ed1-4b83-bc90-5eaadeeb12d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad57896a-9ed1-4b83-bc90-5eaadeeb12d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cedb3437-0503-445f-8102-be4950217d63\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cedb3437-0503-445f-8102-be4950217d63')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cedb3437-0503-445f-8102-be4950217d63 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "embeddings = api.load('word2vec-google-news-300')\n",
        "\n",
        "vec_king = embeddings['king']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr2EBzwCTkpM",
        "outputId": "3f9ab7d8-2755-442c-bb26-922ad3a1053d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "#embeddings = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary = True)\n",
        "\n",
        "#embedding as dictionary\n",
        "\n",
        "\n",
        "word_embeddings = {}\n",
        "for word in embeddings.key_to_index:\n",
        "  word_embeddings[word] = embeddings[word]\n",
        "\n",
        "print(len(word_embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "N1NMskBVTlGN",
        "outputId": "979c2830-85e8-4101-d440-d1c423fd8d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9c8cb744c137>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#embedding as dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \"\"\"\n\u001b[0;32m-> 1719\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1720\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0;31m# deduce both vocab_size & vector_size from 1st pass over file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './GoogleNews-vectors-negative300.bin'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_subset_file = 'word_embeddings_subset.p'\n",
        "embedding_subset_file_path = path.join(resource_path, embedding_subset_file)\n",
        "\n",
        "word_embeddings = pickle.load(open(embedding_subset_file_path, \"rb\"))\n",
        "len(word_embeddings)  # there should be 243 words that will be used in this assignment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oif2CUMfTnbb",
        "outputId": "cfb0d89d-35a9-4884-8d75-fe36d4df1a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "243"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(* word_embeddings.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl5pQ49MTpqR",
        "outputId": "92c62f7f-e1a5-43b3-ab2a-850d244e0689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "country city China Iraq oil town Canada London England Australia Japan Pakistan Iran gas happy Russia Afghanistan France Germany Georgia Baghdad village Spain Italy Beijing Jordan Paris Ireland Turkey Egypt Lebanon Taiwan Tokyo Nigeria Vietnam Moscow Greece Indonesia sad Syria Thailand Libya Zimbabwe Cuba Ottawa Tehran Sudan Kenya Philippines Sweden Poland Ukraine Rome Venezuela Switzerland Berlin Bangladesh Portugal Ghana Athens king Madrid Somalia Dublin Qatar Chile Islamabad Bahrain Nepal Norway Serbia Kabul continent Brussels Belgium Uganda petroleum Cairo Denmark Austria Jamaica Georgetown Bangkok Finland Peru Romania Bulgaria Hungary Vienna Kingston Manila Cyprus Azerbaijan Copenhagen Fiji Tunisia Kazakhstan queen Beirut Jakarta Croatia Belarus Algeria Malta Morocco Rwanda Bahamas Damascus Ecuador Angola Canberra Liberia Honduras Tripoli Slovakia Doha Armenia Taipei Oman Nairobi Santiago Guinea Uruguay Stockholm Slovenia Zambia Havana Uzbekistan Belgrade Mogadishu Khartoum Botswana Kyrgyzstan Dhaka Namibia Ankara Abuja Lima Harare Warsaw Malawi Lisbon Latvia Niger Lithuania Estonia Samoa Oslo Nicaragua Hanoi Sofia Macedonia Senegal Mozambique Guyana Mali Accra Kathmandu Tbilisi Helsinki Montenegro Caracas Laos Budapest Kiev Turkmenistan Eritrea Albania Madagascar Nassau Kampala Amman Greenland Belize Moldova Burundi Tajikistan Baku Astana Gambia Bucharest joyful Monrovia Mauritania Algiers Muscat Bern Luanda Dakar Tunis Gabon Minsk Liechtenstein Suva Yerevan Zagreb Bishkek Manama Kigali Riga Lusaka Tashkent Nicosia Valletta Windhoek Dominica Quito Tallinn Bratislava Tegucigalpa Skopje Gaborone Rabat Maputo Suriname Vilnius Montevideo Ljubljana Tirana Dushanbe Ashgabat Asmara Tuvalu Managua Conakry Banjul Bamako Lilongwe Vientiane Chisinau Roseau Nouakchott Podgorica Niamey Bujumbura Apia Antananarivo Libreville Belmopan Vaduz Paramaribo Nuuk Funafuti\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dimension: {}\".format(word_embeddings['Spain'].shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zLVQbCsTr3D",
        "outputId": "42f16529-a05d-4d82-87e5-fcd6c3bc753f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimension: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use numpy.linalg.norm , numpy.dot\n",
        "\n",
        "\n",
        "def cosine_similarity(A, B):\n",
        "    '''\n",
        "    Input:\n",
        "        A: a numpy array which corresponds to a word vector\n",
        "        B: A numpy array which corresponds to a word vector\n",
        "    Output:\n",
        "        cos: numerical number representing the cosine similarity between A and B.\n",
        "    '''\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "\n",
        "    dot = np.dot(A, B)\n",
        "    norma = np.linalg.norm(A)\n",
        "    normb = np.linalg.norm(B)\n",
        "    cos = dot / (norma * normb)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return cos"
      ],
      "metadata": {
        "id": "BcjcoHBvTtQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feel free to try different words\n",
        "king = word_embeddings['king']\n",
        "queen = word_embeddings['queen']\n",
        "\n",
        "cosine_similarity(king, queen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWDNCGeZTvy_",
        "outputId": "3eaa9e35-bc24-4ce0-ea3f-cf77a8744098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6510956"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use numpy.linalg.norm\n",
        "\n",
        "def euclidean(A, B):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        A: a numpy array which corresponds to a word vector\n",
        "        B: A numpy array which corresponds to a word vector\n",
        "    Output:\n",
        "        d: numerical number representing the Euclidean distance between A and B.\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "\n",
        "    # euclidean distance\n",
        "\n",
        "    d = np.linalg.norm(A - B)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return d"
      ],
      "metadata": {
        "id": "PKckMNctTxeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function\n",
        "euclidean(king, queen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qW9n0CyT2H-",
        "outputId": "ea3999bc-8409-4580-dc3f-69f351d03da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.4796925"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_country(city1, country1, city2, embeddings):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        city1: a string (the capital city of country1)\n",
        "        country1: a string (the country of capital1)\n",
        "        city2: a string (the capital city of country2)\n",
        "        embeddings: a dictionary where the keys are words and values are their embeddings\n",
        "    Output:\n",
        "        countries: a dictionary with the most likely country and its similarity score\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # store the city1, country 1, and city 2 in a set called group\n",
        "    group = set((city1, country1, city2))\n",
        "\n",
        "    # get embeddings of city 1\n",
        "    city1_emb = embeddings.get(city1, None)\n",
        "\n",
        "    # get embedding of country 1\n",
        "    country1_emb = embeddings.get(country1, None)\n",
        "\n",
        "    # get embedding of city 2\n",
        "    city2_emb = embeddings.get(city2, None)\n",
        "\n",
        "    # get embedding of country 2 (it's a combination of the embeddings of country 1, city 1, and city 2)\n",
        "    # Remember: King - Man + Woman = Queen\n",
        "    vec = country1_emb - city1_emb + city2_emb\n",
        "\n",
        "    # Initialize the similarity to -1 (it will be replaced by similarities that are closer to +1)\n",
        "    similarity = -1\n",
        "\n",
        "    # initialize country to an empty string (you will return it as a tuple)\n",
        "    country = ''\n",
        "\n",
        "    # loop through all words in the embeddings dictionary\n",
        "    for word in embeddings.keys():\n",
        "\n",
        "        # first check that the word is not already in the 'group' (it is not a part of input dataset)\n",
        "        if word not in group:\n",
        "\n",
        "            # get the word embedding\n",
        "            word_emb = embeddings[word]\n",
        "\n",
        "            # calculate cosine similarity between the embedding of country 2 and the word in the embeddings dictionary\n",
        "            cur_similarity = cosine_similarity(vec, word_emb)\n",
        "\n",
        "            # if the cosine similarity is more similar than the previously best similarity...\n",
        "            if cur_similarity > similarity:\n",
        "\n",
        "                # update the similarity to the new, better similarity\n",
        "                similarity = cur_similarity\n",
        "\n",
        "                # store the country as a tuple, which contains the word and the similarity\n",
        "                country = (word, similarity)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return country"
      ],
      "metadata": {
        "id": "Eq7DskkbT5La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing your function, note to make it more robust you can return the 5 most similar words.\n",
        "get_country('Athens', 'Greece', 'Cairo', word_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui8LjO-8T7lq",
        "outputId": "c7f3ddfc-2cfb-49ed-bbe3-ab8bbcb37e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Egypt', 0.7626821)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(word_embeddings, data):\n",
        "    '''\n",
        "    Input:\n",
        "        word_embeddings: a dictionary where the key is a word and the value is its embedding\n",
        "        data: a pandas dataframe containing all the country and capital city pairs\n",
        "\n",
        "    Output:\n",
        "        accuracy: the accuracy of the model\n",
        "    '''\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # initialize num correct to zero\n",
        "    num_correct = 0\n",
        "\n",
        "    # loop through the rows of the dataframe\n",
        "    for i, row in data.iterrows():\n",
        "\n",
        "        # get city1\n",
        "        city1 = row['city1']\n",
        "\n",
        "        # get country1\n",
        "        country1 = row['country1']\n",
        "\n",
        "        # get city2\n",
        "        city2 = row['city2']\n",
        "\n",
        "        # get country2\n",
        "        country2 = row['country2']\n",
        "\n",
        "        # use get_country to find the predicted country2\n",
        "        predicted_country2, _ = get_country(city1, country1, city2, word_embeddings)\n",
        "\n",
        "        # if the predicted country2 is the same as the actual country2...\n",
        "        if predicted_country2 == country2:\n",
        "            # increment the number of correct by 1\n",
        "            num_correct += 1\n",
        "\n",
        "    # get the number of rows in the data dataframe (length of dataframe)\n",
        "    m = len(data)\n",
        "\n",
        "    # calculate the accuracy by dividing the number correct by m\n",
        "    accuracy = num_correct / m\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "QwKGwNKKT-PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = get_accuracy(word_embeddings, data)\n",
        "print(f\"Accuracy is {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pI3XdGCUAbK",
        "outputId": "dbe7ae16-9d1c-4de3-8fbc-ad2f70921676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_closest_word(v, excluded_word, embeddings):\n",
        "    closest_word = None\n",
        "    min_distance = float('inf')\n",
        "\n",
        "    for word in embeddings.index_to_key:\n",
        "        if word == excluded_word:\n",
        "            continue\n",
        "\n",
        "        word_emb = embeddings[word]\n",
        "        distance = np.linalg.norm(v - word_emb)\n",
        "\n",
        "        if distance < min_distance:\n",
        "            closest_word = word\n",
        "            min_distance = distance\n",
        "    return closest_word"
      ],
      "metadata": {
        "id": "b-l09NoNUC-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rel_src1 = 'fast'\n",
        "rel_trg1 = 'slow'\n",
        "rel_src2 = 'clever'\n",
        "test_vector = embeddings[rel_src1] - embeddings[rel_trg1] + embeddings[rel_src2]\n",
        "def get_analogy(rel_src1, rel_trg1, rel_src2, embeddings):\n",
        "    # Calculate the vector representation of the analogy\n",
        "    analogy_vector = embeddings[rel_trg1] - embeddings[rel_src1] + embeddings[rel_src2]\n",
        "\n",
        "    # Find the closest word to the analogy vector, excluding the source word\n",
        "    rel_trg2 = find_closest_word(analogy_vector, rel_src2, embeddings)\n",
        "\n",
        "    return rel_trg2"
      ],
      "metadata": {
        "id": "ooxFMPgJUFNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_analogy(rel_src1, rel_trg1, rel_src2, embeddings)\n",
        "\n",
        "print(f\"{rel_src1} is to {rel_trg1} as {rel_src2} is to {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTd7Fhc6aXxM",
        "outputId": "93925322-541b-496d-8a35-377e35c57729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fast is to slow as clever is to clumsy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rel=('fast', 'slow', 'clever')  #fast to slow is like clever to"
      ],
      "metadata": {
        "id": "ctPoiIxkUHwa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}